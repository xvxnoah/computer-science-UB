{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fb6598",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------\n",
    "<h1><center>\n",
    "    \n",
    "Practical exam on Computer Vision: Part II\n",
    "    \n",
    "(January, 18th, 2024)\n",
    "</center></h1>   \n",
    "\n",
    "Consider the following:\n",
    "\n",
    "- You can answer in English, Spanish or Catalan. \n",
    "\n",
    "- Add title to figures and add sufficient comments on the code to understand it.\n",
    "\n",
    "- Make sure to print and plot exactly what it is indicated. If a reference image is provided, your output is expected to be exactly the same unless instructed differently. \n",
    "\n",
    "- At the end of the exam, upload only your .ipynb file (no need to upload the images)\n",
    "    \n",
    "- Make sure your code can be ran by us without errors.\n",
    "\n",
    "- Use packages and solutions that were covered in your class and tutorials. If you are unsure about using a particular package, you should seek clarification from your instructor to confirm whether it is allowed.\n",
    "\n",
    "- Please note that partial credit will be given based on the correctness of the code and the logic demonstrated. If certain parts of your code or answers are accurate, even if the final output is not entirely correct, you may still receive points.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a022c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that can be helpful for this exam:\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import io, img_as_ubyte, img_as_float\n",
    "from skimage.io import imsave, imread\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.feature import hog\n",
    "import matplotlib.patches as patches\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import integral_image\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af144e7",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745741a4",
   "metadata": {},
   "source": [
    "### Improving the HOG detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226ffb3",
   "metadata": {},
   "source": [
    "A collaboration has been initiated between several departments at the University of Barcelona and a big company. As part of the collaboration, an exercise has been assigned to assess potential new team members. This exercise is a modified version of one covered in class. \n",
    "\n",
    "In the earlier task, we examined the effectiveness of the HOG descriptor in person detection by employing a uniform template across various images. Now, we aim to deepen its understanding by comparing the impact of using different templates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460b9c2",
   "metadata": {},
   "source": [
    "**Ex.1.1** (1 points) Load the images `silhouette_cropped.png`, `person_template1.bmp` and `person_template2.png` from the folder `images`. Obtain their HOG descriptors and visualize them. Use the default parameters of the HOG function. Take as an example the following image:\n",
    "\n",
    "<img src=\"images/exercise11.png\" width=\"515\" height=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f8a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a5567",
   "metadata": {},
   "source": [
    "**Ex.1.2** (2 points) Apply the previous templates to the image: `images/TestPersonImages/person_027.bmp`. Read the image and slide a window on each template to store the most similar Region of Interest, using Norm 2 (np.linalg.norm). Visualize the images in a 1x3 grid of images, like in the example below. All the images have been resized to accelerate the computation. All the images should be transformed to grayscale.\n",
    "\n",
    "*Hint*: This exercise could take up a few seconds running, however it should not take minutes.\n",
    "<img src=\"images/exercise12.png\" width=\"515\" height=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f16f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6044d3",
   "metadata": {},
   "source": [
    "Which template has been the best choice for the detection task? Has the difference between the templates and images raised any challenges in any of the cases? The images are smaller in size than the ones used in class. Has this influenced the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61f44f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99245952",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ee43b",
   "metadata": {},
   "source": [
    "### Autonomous cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04e4ee",
   "metadata": {},
   "source": [
    "A big car company has started a proyect to create autonomous cars. The autonomous car market is quite advanced, and they are working around the clock to catch up with their competitors and establish themselves as a leading brand in autonomous electric vehicles by 2026. The goal is to recognize different vehicles on the road to react to unforeseen events. Considering your performance in the previous task, you are now a member of this team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386caf1",
   "metadata": {},
   "source": [
    "**Ex 2.1** (2 points) Read the images from the directories `./images/vehicles/bike`, `./images/vehicles/boat`, `./images/vehicles/bus`, `./images/vehicles/car`, `./images/vehicles/cycle`. Transform the RGB images to grayscale and resize them to 100x100 pixels (to reduce computation time). Build two arrays: one, X, with all the features, and the other, y, containing the label of the images. The class_labels for the images should be: 0 = bike, 1 = boat, 2 = bus, 3 = car, 4 = cycle.\n",
    "\n",
    "To check the correctness of the exercise, visualize the images number 0, 150 and 300, along with their type. The next image is an example of the result:\n",
    "\n",
    "<img src=\"images/exercise21.png\" width=\"515\" height=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02e96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778c3d10",
   "metadata": {},
   "source": [
    "**Ex 2.2** (1,5 points) Divide the dataset into train set and test set, the test set size being the 30% of the total dataset. Create a PCA object of 50 components and visualize 20 principal components.\n",
    "​\n",
    "The next image is an example of the result:\n",
    "​\n",
    "<img src=\"images/exercise32.png\" width=\"515\" height=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccdfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8796a75",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc74b5",
   "metadata": {},
   "source": [
    "### Introducing the AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f3b5d",
   "metadata": {},
   "source": [
    "The perfomance in the previous exercise has been better than expected. The board of inverstors is happy with your achievements and have moved the release date of the new software from 2026 to 2025. That means there is more work to do: you now need to create an algorithm able to classify a larger volume of images. Currently, you will continue using the same set of images as in the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa07a01",
   "metadata": {},
   "source": [
    "**Ex 3.1** (2 points) Use the images from the previous directories `./images/vehicles/bike`, `./images/vehicles/boat`, `./images/vehicles/bus`, `./images/vehicles/car`, `./images/vehicles/cycle`. Resize them to 15x15 pixels (to reduce computation time even more). Build an array X, using the built `extract_feature_image` method seen in P5, with all the given Haar-like features (which are usually used for faces).\n",
    "                 \n",
    "Print the shape of both arrays. The shape of X should be (305, 78460), and the shape of y (305,).\n",
    "\n",
    "```python\n",
    "feature_types = ['type-2-x', 'type-2-y',\n",
    "                 'type-3-x', 'type-3-y',\n",
    "                 'type-4']\n",
    "```\n",
    "\n",
    "*Hint*: This exercise could take up a few seconds running, however it should not take minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eaef839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2031954",
   "metadata": {},
   "source": [
    "**Ex 3.2** (1,5 points) Train an Adaboost classifier with 10 estimators. Use the *predict* and *score* methods of the classifier to evaluate the testing accuracy *(percentage of correctly classified images)*. The test size must be the 30% (i.e. 0.3) of the whole dataset. Use the ``train_test_split()`` function from `sklearn.model_selection`. The labels used in this function should be the same as in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d771a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
